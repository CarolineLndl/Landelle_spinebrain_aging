{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=#B2D732> <span style=\"background-color: #4424D6\">  Brain and spinal cord fMRI denoising </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@ author of the script:  <font color=#B2D732> Caroline Landelle </font>, caroline.landelle@mcgill.ca // landelle.caroline@gmail.com   \n",
    "@ Contribution and adjustements: <font color=#B2D732>  Nawal Kinany </font>, nawal.kinany@epfl.ch  \n",
    "\n",
    "**Description:** This notebook provides code for BOLD signal fMRI resting-state denoising, template registration and smoothing  \n",
    "see Landelle et al. 2023:   \n",
    "*For each individual, we accounted for the physiological and other noise sources by modeling nuisance noises present in CSF and by collecting physiological data using the Tapas PhysiO toolbox (Kasper et al., 2017). First, we used the RETROspective Image CORrection (RETROICOR) procedure (Glover et al., 2000) [..] Second, [...] we used the CompCor (Behzadi et al., 2007) approach [...]. Finally, we applied a bandpass filter 0.01-0.17 Hz to emphasize low-frequency signals of interest.*\n",
    "\n",
    "> <font color=#B2D732> **I.** </font> **Denoising: Retroicor + Compcor**  \n",
    "> <font color=#B2D732> **II.** </font> **DCT calculation**  \n",
    "> <font color=#B2D732> **III.** </font> **Signal cleaning**  \n",
    "> <font color=#B2D732> **IV.** </font> **Normalization to template**  \n",
    "> <font color=#B2D732> **V.** </font> **Smoothing**  \n",
    "> <font color=#B2D732> **VI.** </font> **Concatenation: Brain + Spinal cord image**  \n",
    "   \n",
    "**Toolbox required:** Tapas PhysiO Toolbox (SPM, Matlab) , nilearn (Python), FSL (bash)  \n",
    "https://github.com/translationalneuromodeling/tapas/tree/master/PhysIO  \n",
    "https://www.sciencedirect.com/science/article/pii/S016502701630259X  \n",
    "\n",
    "**Inputs**:  \n",
    "This notebook required this the following prepross anatomical, fmri images and physiological recoridings\n",
    "\n",
    "\n",
    "**Ouputs**:\n",
    "See the output description at each step of the Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#B2D732> <span style=\"background-color: #4424D6\"> Initialization </font>  \n",
    "Before running the script you should create a config.json file with the right pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Main imports ------------------------------------------------------------\n",
    "import sys,json, glob, os, shutil\n",
    "import matlab.engine\n",
    "import nibabel as nb\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "\n",
    "# homemade functions -------------------------------------------------------------\n",
    "code_dir=\"/cerebro/cerebro1/dataset/bmpd/derivatives/Aging_project/2025_brsc_aging_project/\"\n",
    "os.chdir(code_dir)\n",
    "sys.path.append(code_dir + \"/code/\") # Change this line according to your directory\n",
    "\n",
    "from brsc_denoising import Denoising\n",
    "import brsc_utils as utils\n",
    "from brsc_preprocess import Preprocess_Sc, Preprocess_Br,Preprocess_BrSc\n",
    "\n",
    "# Load config file ------------------------------------------------------------\n",
    "with open(code_dir + '/config/preprocessing/02_brsc_denoising.json') as config_file: # the notebook should be in 'xx/notebook/' folder #config_proprio\n",
    "    config = json.load(config_file) # load config file should be open first and the path inside modified\n",
    "with open(code_dir + '/config/preprocessing/01_brsc_preprocess_func.json') as config_file: # the notebook should be in 'xx/notebook/' folder #config_proprio\n",
    "    config_preproc = json.load(config_file) # load config file should be open first and the path inside modified\n",
    "\n",
    "denoising=Denoising(config)\n",
    "\n",
    "preprocess_Sc=Preprocess_Sc(config_preproc)\n",
    "preprocess_Br=Preprocess_Br(config_preproc)\n",
    "preprocess_BrSc=Preprocess_BrSc(config_preproc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#B2D732> <span style=\"background-color: #4424D6\"> I. Outliers calculation based on DVARS </font> \n",
    "> Volumes in which scan-to-scan displacement exceeded 1 mm were then detected and included as noise regressors during the denoising step   \n",
    "> Calculate DVARS [FSL, fsl_motion_outliers] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### maybe recalcultate them slice wise :)\n",
    "outliers={}\n",
    "for structure in config[\"structures\"]:\n",
    "    outliers[structure]=[]\n",
    "    for ID in config[\"participants_IDs\"]:\n",
    "        outliers[structure].append(denoising.outliers(ID=ID,structure=structure,redo=False))\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#B2D732> <span style=\"background-color: #4424D6\"> II. File preparation </font> </span> \n",
    "> <font color=#B2D732> 1. </font>  **Unzip data for SPM**    \n",
    "> <font color=#B2D732> 2. </font>  **Create denoising directories  & copy.tsv files**     \n",
    "> <font color=#B2D732> 3. </font>  **Create slice wise motion parameter .tsv file**     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=#4424D6> II.1 Unzip SPM data </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csf_infunc_files={}\n",
    "for structure in config[\"structures\"]:\n",
    "    csf_infunc_files[structure]=[]\n",
    "    for ID in config[\"participants_IDs\"]:\n",
    "        for run_nb,run in enumerate(config[\"design_exp\"][\"ses_names\"]):\n",
    "            main_dir=config[\"preproc_dir_bmpd\"] if ID[0]==\"P\" else config[\"preproc_dir\"]\n",
    "            csf_infunc_file=glob.glob(main_dir + config[\"seg_files\"][structure][\"csf_infunc\"].format(ID,run))[0]\n",
    "            csf_infunc_files[structure].append(utils.unzip_file(csf_infunc_file,ext='.nii',redo=False,verbose=False)) # do not redo for spinalcord before corrected manually the CSF mask "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=#4424D6> II.2 Create denoising directories  & copy.tsv files </font>\n",
    "Copy and unzippe physio files. Note that the physio files should be in .tsv (BIDS) or log format before running that script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physio_files=[]\n",
    "for ID in config[\"participants_IDs\"]:\n",
    "    for run_nb,run in enumerate(config[\"design_exp\"][\"ses_names\"]):\n",
    "        physio_files.append(denoising.find_physio_file(ID=ID,\n",
    "                                                       run_name=run,\n",
    "                                            copy=True, # if you want to copy the data somewhere else than the rawdata directory\n",
    "                                            output_dir=config[\"denoising\"][\"dir\"].format(ID,run), #  needed if copy=True \n",
    "                                            redo=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=#4424D6> II.3 Create slice wise motion parameter .tsv file  </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for structure in config[\"structures\"]:\n",
    "    for ID in config[\"participants_IDs\"]:\n",
    "        for run_nb,run in enumerate(config[\"design_exp\"][\"ses_names\"]):\n",
    "            denoising.moco_params(ID=ID, run_name=run,structure=structure,redo=False)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#B2D732> <span style=\"background-color: #4424D6\"> III. Run Retroicor </font> </span> \n",
    "*We used the RETROspective Image CORrection (RETROICOR) procedure (Glover et al., 2000) to generate noise regressors from peripheral physiological recordings. This method models the respiratory and cardiac phases for each functional volume. A low-order Fourier expansion was then calculated to model the physiological noise. We modeled six cardiac and eight respiratory harmonics and four multiplicative terms for the interactions between cardiac and respiratory noise, as well as one regressor for heart rate variability and one for the respiratory volume per time.  \n",
    "NEW !! The outputs are generated slice wise*\n",
    "\n",
    "/!\\ If there is a beug like \"No peaks found in raw cardiac time series. Check raw physiological recordings figure whether there is any non-constantcardiac data\" it is possible that you have NaN in your physio file.\n",
    "\n",
    "<span style=\"background-color: #FFFACD\"> <font color=#efb017> /!\\ </font>  **Check point:**  physiological recording graph:  *sub-XX_Physio.png* </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(code_dir +'/code/spm/')# need to change the directory to find the toolbox\n",
    "eng = matlab.engine.start_matlab()\n",
    "\n",
    "for structure in config[\"structures\"]:\n",
    "    physio_mat={}\n",
    "    for run_nb, run_name in enumerate(config[\"design_exp\"][\"ses_names\"]):\n",
    "        physio_mat[run_name]=[]\n",
    "        for ID_nb, ID in enumerate(config[\"participants_IDs\"]):\n",
    "            preproc_dir=config[\"preproc_dir_bmpd\"] if ID[0]==\"P\" else config[\"preproc_dir\"]\n",
    "            #A. Run TAPAS_________________________________________\n",
    "            PhysioDir=config[\"denoising\"][\"dir\"].format(ID,run_name) +structure +'/confounds/' # output directory\n",
    "\n",
    "            nb_slices = nb.load(glob.glob(preproc_dir + config[\"moco_files\"][\"dir\"].format(ID,run_name,structure) + config[\"moco_files\"][\"moco_mean_f\"])[0]).shape[2] # extract number of slices\n",
    "           \n",
    "            if len(physio_files[ID_nb])==2:\n",
    "                resp_file=physio_files[ID_nb][0];cardio_file=physio_files[ID_nb][1];\n",
    "            else:\n",
    "                resp_file=physio_files[ID_nb];cardio_file=physio_files[ID_nb];\n",
    "            \n",
    "            utils.unzip_file(glob.glob(preproc_dir + config[\"moco_files\"][\"dir\"].format(ID,run_name,structure) + config[\"moco_files\"][\"moco_f\"])[0],\n",
    "                             ext='_SPM.nii',redo=False) #unzip moco if it was not already done\n",
    "            \n",
    "            tapas_outfile_name='_18_retroicor_' +structure\n",
    "            \n",
    "        \n",
    "            if not os.path.exists(PhysioDir +  'sub-'+ ID +  tapas_outfile_name +'_slice001.txt'):\n",
    "                print(eng.TapasPhysiO(ID, # sub_name\n",
    "                                      preproc_dir + config[\"moco_files\"][\"dir\"].format(ID,run_name,structure), # inputDir : Moco directory\n",
    "                                      os.path.basename(glob.glob(preproc_dir + config[\"moco_files\"][\"dir\"].format(ID,run_name,structure) + config[\"moco_files\"][\"moco_f\"])[0]).split('.')[0] + '_SPM.nii', #func_img : Moco file unzipped\n",
    "                                      config[\"acq_params\"][\"TR\"], # TR ,\n",
    "                                      config[\"acq_params\"][\"physio_frq\"][0],\n",
    "                                      config[\"acq_params\"][\"physio_json\"],# set to 1 in you have json file related to physio files\n",
    "                                      nb_slices, #nb_slices: number of slices\n",
    "                                      \"\",#csf_infunc_files[structure][ID_nb], #csf_mask : unzipped CSF in func image\n",
    "                                      cardio_file ,\n",
    "                                      resp_file , \n",
    "                                      \"\", # no timing is privided\n",
    "                                      tapas_outfile_name, #outfile_name name of the outputfile\n",
    "                                      PhysioDir,# outputDir\n",
    "                                      config)) # config file\n",
    "                print('for ' + ID  + ' ' +structure )\n",
    "                print('**************************************************')\n",
    "            else:\n",
    "                print('Tapas already done for ' + ID + ' '   + structure )\n",
    "                print('**************************************************')\n",
    "\n",
    "            for slice_nb in range(1,nb_slices):\n",
    "                slice_str=\"00\" + str(slice_nb + 1) if (slice_nb+1)<10 else \"0\" + str(slice_nb+1)\n",
    "                mat_file=PhysioDir +  'sub-'+ ID +  tapas_outfile_name +'_slice'+slice_str+'.mat'\n",
    "                if os.path.exists(mat_file):\n",
    "                    os.remove(mat_file) # remove all mat files exept for the first slice as they are havy\n",
    "            \n",
    "            denoising.plot_physio(glob.glob(PhysioDir+'*retroicor*.mat')[0],\n",
    "                             PhysioDir,\n",
    "                              ID=ID,\n",
    "                              save=True) # to plot and save physio put save=True\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#B2D732> <span style=\"background-color: #4424D6\"> III. CompCor and DCT calculation </font> </span> \n",
    "1. Discrete cosine transform (DCT) expresses a finite sequence of data points in terms of a sum of cosine functions oscillating at different frequencies.  The DCT is similar to the discrete Fourier transform: it transforms a signal from the spatial domain to the frequency domain. DCT improve the denoising, we found a significant improvement for iCAPS analyses\n",
    "2. Second, to eliminate the non-neural aspects of the signal, we used the CompCor (Behzadi et al., 2007) approach by extracting the mean signal and the first five principal components of the unsmoothed signal recorded from the CSF (CSF-mask in functional space)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCT_files={}; compcor_files={};\n",
    "for structure in config[\"structures\"]:\n",
    "    compcor_files[structure]=[];DCT_files[structure]=[]\n",
    "    print(structure)\n",
    "    for run_nb,run in enumerate(config[\"design_exp\"][\"ses_names\"]):\n",
    "        for ID_nb, ID in enumerate(config[\"participants_IDs\"]):\n",
    "            print(ID)\n",
    "            preproc_dir=config[\"preproc_dir_bmpd\"] if ID[0]==\"P\" else config[\"preproc_dir\"]\n",
    "            #print(main_dir + config[\"seg_files\"][structure][\"dir_func\"].format(ID) + config[\"seg_files\"][structure][\"seg_func\"])\n",
    "            compcor_comp,DCT_comp=denoising.confounds_ts(ID=ID,\n",
    "                                                         run_name=run,\n",
    "                                                         func_file=glob.glob(preproc_dir + config[\"moco_files\"][\"dir\"].format(ID,run,structure) + config[\"moco_files\"][\"moco_f\"])[0],\n",
    "                                                         mask_csf_file=csf_infunc_files[structure][ID_nb],\n",
    "                                                         mask_seg_file=glob.glob(preproc_dir + config[\"seg_files\"][structure][\"seg_func\"].format(ID,run))[0],\n",
    "                                                         n_compcor=5 if structure==\"spinalcord\" else 12,\n",
    "                                                         structure=structure,\n",
    "                                                         compcor=True,\n",
    "                                                         DCT=True,\n",
    "                                                         redo=False)\n",
    "            compcor_files[structure].append(compcor_comp)\n",
    "            DCT_files[structure].append(DCT_comp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#B2D732> <span style=\"background-color: #4424D6\"> IV. Clean functional data </font> </span> \n",
    "### <font color=#4424D6> IV.1 Grouped confounds for brain and spinal cord separatly</font>\n",
    "<span style=\"background-color: #FFFACD\"> <font color=#efb017> **/!\\**  </font>  **Check point** the denoising matrices  </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confounds={}\n",
    "confound_infos={};Counfounds_allsbj={}\n",
    "for structure in config[\"structures\"]:\n",
    "    confounds[structure]=[]\n",
    "    print(structure)\n",
    "    for run_nb,run in enumerate(config[\"design_exp\"][\"ses_names\"]):\n",
    "        for ID_nb, ID in enumerate(config[\"participants_IDs\"]):\n",
    "            print(ID)\n",
    "    \n",
    "            confound_infos['brain']={'Outliers':1,'moco':2,'retroicor':18,'compcor':12,'DCT':3}\n",
    "            confound_infos['spinalcord']={'Outliers':1,'moco':2,'retroicor':18,'compcor':5,'DCT':3}\n",
    "            confounds[structure].append(denoising.combine_confounds(ID=ID,\n",
    "                                                                    run_name=run,\n",
    "                                                                        confounds_infos=confound_infos[structure],\n",
    "                                                                        structure=structure,\n",
    "                                                                        retroicor_confounds=True,\n",
    "                                                                        compcor_confounds=True,\n",
    "                                                                        moco_confounds=True,\n",
    "                                                                        outliers_confounds=outliers[structure][ID_nb],\n",
    "                                                                        DCT_confounds=True,\n",
    "                                                                        slice_wise=True,\n",
    "                                                                        redo=False))\n",
    "                \n",
    "            denoising.plot_confound_design(ID=ID,\n",
    "                                               confound_file=confounds[structure][ID_nb][1].split(\"_slice\")[0] + \"_slice020_z.txt\",\n",
    "                                               confounds_infos=confound_infos[structure],\n",
    "                                               structure=structure,\n",
    "                    save=True)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### <font color=#4424D6> III.2 Grouped confounds for brain and spinal cord concomitantly </font>\n",
    "I removed that step since is slice wise corrected\n",
    "<span style=\"background-color: #FFFACD\"> <font color=#efb017> **/!\\**  </font>  **Check point** the denoising matrices  </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#B2D732> <span style=\"background-color: #4424D6\"> IV. Image Cleaning </font> \n",
    "> Here we are going to remove the confounds that we extracted and merge below.  \n",
    "> The denoising will be run for each slice  \n",
    ">  If you want to filter the data you should apply a BP: [0.01-0.017] Hz or HP filtering only before running icaps.  \n",
    "    \n",
    "According to Lindquist et al. (2018), removal of confounds will be done orthogonally to temporal filters (low- and/or high-pass filters), if bothare specified.\n",
    "\n",
    "*note to myself:*  \n",
    "Brain:  0 outliers + 6  motion param + 18 retroicor + 12 compcor + 3 DCT + [0.01] hz or [0.01-0.017] hz  \n",
    "Spinal cord:  0 outliers + 2  motion param + 18 retroicor + 5 compcor + 3 DCT + [0.01] hz or [0.01-0.017] hz  \n",
    "       \n",
    "<span style=\"background-color: #FFFACD\"> <font color=#efb017> **/!\\**  </font>  **Check point** check denoised images  </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Clean_image_file={};Clean_meanimage_file={};\n",
    "filtering_params = {\n",
    "    \"BP\": {\"high_pass\": 0.01, \"low_pass\": 0.17},\n",
    "    \"HP\": {\"high_pass\": 0.01, \"low_pass\": None},\n",
    "    \"nofilter\": {\"high_pass\": None, \"low_pass\": None}}\n",
    "\n",
    "\n",
    "for structure in config[\"structures\"]:\n",
    "    print(structure)\n",
    "    Clean_image_file[structure]={}; Clean_meanimage_file[structure]={}\n",
    "    for filtering in [\"nofilter\"]:#,\"BP\",\"nofilter\",\"HP\"]:\n",
    "        Clean_image_file[structure][filtering]=[]\n",
    "        for run_nb,run in enumerate(config[\"design_exp\"][\"ses_names\"]):\n",
    "            for ID_nb, ID in enumerate(config[\"participants_IDs\"]):\n",
    "                print(ID)\n",
    "                preproc_dir=config[\"preproc_dir_bmpd\"] if ID[0]==\"P\" else config[\"preproc_dir\"]\n",
    "                Clean_image_file[structure][filtering].append(denoising.clean_images(\n",
    "                    ID=ID,\n",
    "                    run_name=run,\n",
    "                    confounds_file=confounds[structure][ID_nb][0],\n",
    "                    mask_file=glob.glob(preproc_dir + config[\"seg_files\"][structure][\"seg_func\"].format(ID,run))[0],\n",
    "                    #mask_file=glob.glob(preproc_dir + config[\"seg_files\"][structure][\"seg_func\"].format(ID,run).split(\".\")[0] + \"_dilated.nii.gz\")[0],\n",
    "                    structure=structure,\n",
    "                    high_pass=filtering_params[filtering][\"high_pass\"],\n",
    "                    low_pass= filtering_params[filtering][\"low_pass\"], \n",
    "                    tag_name=filtering + \"_nostd\" , #std means the data were z-scored\n",
    "                    standardize=False,#\"zscore\", # False if you don't want\n",
    "                    n_jobs=4,redo=False))\n",
    "                          \n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#B2D732> <span style=\"background-color: #4424D6\"> V. Normalization to template </font>  \n",
    "The denoised data are normalise in template space (Using spline).\n",
    "For brain images we should first coregister to the anat. Then from anat space to MNI\n",
    "For sc images the warping field already include the func_T1w transformation and anat to PAM50 transformation\n",
    "\n",
    "<span style=\"background-color: #FFFACD\"> <font color=#efb017> **/!\\**  </font>  **Check point** normalised images  </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Norm_Clean_file={};Coreg_Clean_file={}\n",
    "for structure in config[\"structures\"]:\n",
    "    if structure ==\"spinalcord\":\n",
    "        #os.system('find /tmp /var/tmp -maxdepth 1 -user landelle -exec rm -rf {} \\;')\n",
    "        #os.system('find /tmp /var/tmp /export02/data/tmp -maxdepth 1 -user landelle -exec rm -rf {} \\;')\n",
    "        warp_f=[];Norm_Clean_file[structure]={};o_folders=[];dest_img=[]\n",
    "        for filtering in [\"nofilter\"]:#,\"BP\",\"HP\"]:\n",
    "            for run_nb,run in enumerate(config[\"design_exp\"][\"ses_names\"]):\n",
    "                for ID_nb, ID in enumerate(config[\"participants_IDs\"]):\n",
    "                    print(ID)\n",
    "                    preproc_dir=config[\"preproc_dir_bmpd\"] if ID[0]==\"P\" else config[\"preproc_dir\"]\n",
    "                    warp_f.append(glob.glob(preproc_dir + config[\"normalization\"][\"spinalcord\"][\"warp_f\"].format(ID,run))[0])\n",
    "                    o_folders.append(config[\"normalization\"][\"dir\"].format(ID,run_name)+ structure + \"/\")\n",
    "                    dest_img.append(config[\"tools_dir\"][\"main_codes\"] +  config[\"PAM50_t2\"])\n",
    "               \n",
    "                #Norm_Clean_file[structure][filtering]=\n",
    "                Norm_Clean_file[structure][filtering]=preprocess_Sc.apply_warp(\n",
    "                        i_img=Clean_image_file[structure][filtering], # input clean image\n",
    "                        ID=config[\"participants_IDs\"],\n",
    "                        o_folder=o_folders, # output folder\n",
    "                        dest_img=dest_img, # PAM50 template\n",
    "                        warping_field=warp_f,\n",
    "                        tag=\"_inTemplate\",\n",
    "                        mean=True,\n",
    "                        n_jobs=4,redo=False)\n",
    "    \n",
    "    elif structure==\"brain\":\n",
    "        Coreg_Clean_file[structure]={}; Norm_Clean_file[structure]={}\n",
    "        for filtering in [\"nofilter\"]:#,\"BP\",\"HP\"]:\n",
    "            Coreg_Clean_file[structure][filtering]=[]; Norm_Clean_file[structure][filtering]=[]\n",
    "            warp_f=[]\n",
    "            #1. run coregistration between the func and anat image\n",
    "            \n",
    "            for ID_nb, ID in enumerate(config[\"participants_IDs\"]):\n",
    "                \n",
    "                # coregister mean image into T1w image\n",
    "                preproc_dir=config[\"preproc_dir_bmpd\"] if ID[0]==\"P\" else config[\"preproc_dir\"]\n",
    "                warp_f.append(glob.glob(config[\"preproc_dir\"] + config[\"normalization\"][structure][\"warp_f\"].format(ID,run))[0])\n",
    "    \n",
    "                # coregister mean image into T1w image\n",
    "                Coreg_Clean_file[structure][filtering].append(preprocess_Br.coregistration_func2anat(ID=ID,\n",
    "                                                                     func_img=glob.glob(preproc_dir + config[\"moco_files\"][\"dir\"].format(ID,run,structure) + config[\"moco_files\"][\"moco_mean_f\"])[0],\n",
    "                                                                     anat_img=glob.glob(preproc_dir+ config[\"normalization\"][\"brain\"][\"T1w_native\"].format(ID))[0],\n",
    "                                                                     filenames_func4D=Clean_image_file[structure][filtering][ID_nb],\n",
    "                                                                     o_folder=config[\"normalization\"][\"dir\"].format(ID) + \"/brain/\",\n",
    "                                                                     tag=\"_inT1w\",redo=False,verbose=False))\n",
    "                \n",
    "                #2. run normalization between the func and MNI space using dartel template\n",
    "                print(config[\"tools_dir\"][\"main_codes\"] + \"/template/\"+ config[\"MNI_mask\"])\n",
    "                print(Coreg_Clean_file[structure][filtering][ID_nb][1])\n",
    "                Norm_Clean_file[structure][filtering].append(preprocess_Br.dartel_norm(ID=ID,\n",
    "                                                      dartel_template=glob.glob(config[\"normalization\"][\"brain\"][\"dartel_dir\"].format(config[\"normalization\"][\"brain\"][\"dartet_tag\"]))[0],\n",
    "                                                      warp_file=glob.glob(warp_f[ID_nb])[0],\n",
    "                                                      i_file=glob.glob(Coreg_Clean_file[structure][filtering][ID_nb][1])[0],\n",
    "                                                      o_file=Coreg_Clean_file[structure][filtering][ID_nb][1].split(\".\")[0] + \"_inTemplate.nii\",\n",
    "                                                       brain_mask=config[\"tools_dir\"][\"main_codes\"] +  config[\"MNI_mask\"],\n",
    "                                                     redo=False))\n",
    "\n",
    "                print(Norm_Clean_file[structure][filtering])          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#std could be apply before or after smoothing, depending on the analysis\n",
    "std_Clean_file={}\n",
    "for structure in config[\"structures\"]:\n",
    "    std_Clean_file[structure]=[];mask=[]\n",
    "    for ID_nb, ID in enumerate(config[\"participants_IDs\"]):\n",
    "        std_Clean_file[structure].append(Norm_Clean_file[structure][filtering][ID_nb].split(\"HP_\")[0]+filtering +\"_std_inTemplate.nii.gz\")\n",
    "\n",
    "        if structure ==\"brain\":\n",
    "            mask.append(config[\"tools_dir\"][\"main_codes\"] +config[\"MNI_mask\"])\n",
    "        elif structure==\"spinalcord\":\n",
    "            mask.append(config[\"tools_dir\"][\"main_codes\"] + config[\"PAM50_cord\"])\n",
    "        \n",
    "    denoising.standardize(input_files=Norm_Clean_file[structure][filtering],output_files=std_Clean_file[structure],redo=True,mask_files=mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#B2D732> <span style=\"background-color: #4424D6\"> VI. Smoothing </font> \n",
    "Smoothing is a regularization of the model that decrease the noise level in images, and reduce the discrepancy between individuals. \n",
    "We use two differents smoothing for brain and spinal cord, full-width at half maximum (FWHM).  \n",
    "> Brain: 6x6x6 mm isotropic  \n",
    "> Spinalcord: 3x3x6 mm anisotropic  \n",
    "\n",
    "<span style=\"background-color: #FFFACD\"> <font color=#efb017> **/!\\**  </font>  **Check point** smoothed images  </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#double cjeck\n",
    "Smoothed_Clean_file={}\n",
    "for structure in config[\"structures\"]:\n",
    "    fwhm=[6,6,6] if structure ==\"brain\" else [3,3,6]\n",
    "    o_folders=[];Smoothed_Clean_file[structure]=[]\n",
    "    for ID_nb, ID in enumerate(config[\"participants_IDs\"]):\n",
    "        o_folders.append(config[\"smoothing\"][\"dir\"].format(ID)+ structure + \"/\")\n",
    "\n",
    "    \n",
    "    Smoothed_Clean_file[structure]=preprocess_BrSc.smooth_img(i_img=Norm_Clean_file[structure][filtering],\n",
    "                                                              o_folder=o_folders,\n",
    "                                                                     ID=config[\"participants_IDs\"],\n",
    "                                                                     fwhm=fwhm,n_jobs=8,redo=False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#B2D732> <span style=\"background-color: #4424D6\"> VII. Standardize </font>\n",
    "the standardization is needed for the icaps analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#redo 31\n",
    "std_Clean_file={}\n",
    "\n",
    "for structure in config[\"structures\"]:\n",
    "    std_Clean_file[structure]=[];mask=[]\n",
    "    for ID_nb, ID in enumerate(config[\"participants_IDs\"]):\n",
    "        std_Clean_file[structure].append(Smoothed_Clean_file[structure][ID_nb].split(\".nii.gz\")[0]+\"_std.nii.gz\")\n",
    "\n",
    "        if structure ==\"brain\":\n",
    "            mask.append(config[\"tools_dir\"][\"main_codes\"] +  config[\"MNI_mask\"])\n",
    "        elif structure==\"spinalcord\":\n",
    "            mask.append(config[\"tools_dir\"][\"main_codes\"] +  config[\"PAM50_cord\"])\n",
    "        \n",
    "    denoising.standardize(input_files=Smoothed_Clean_file[structure],output_files=Smoothed_Clean_file[structure],redo=True,mask_files=mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 185,
   "position": {
    "height": "40px",
    "left": "908px",
    "right": "20px",
    "top": "29px",
    "width": "338px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
